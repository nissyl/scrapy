{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflowを用いた強化学習の実装\n",
    "\n",
    "機械学習用ライブラリTensorflowを用いて、Pythonで強化学習を実装します。<br>\n",
    "今回のハンズオンでは、五目並べんお実装とモンテカルロ法によって自己対戦で強化学習をさせます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anm\n",
    "from PIL import Image, ImageDraw\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: tensorflow: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!pip  --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 8\n",
    "\n",
    "# 五目並べのプログラム\n",
    "class Game:\n",
    "    # コンストラクタ\n",
    "    def __init__(self):\n",
    "        self.size = size\n",
    "        self.square = [[0 for _ in range(self.size)] for _ in range(self.size)]\n",
    "        self.turn = 1\n",
    "    # 石を置く\n",
    "    def put(self, row, column):\n",
    "        if 0 <= row < self.size and 0 <= column < self.size:\n",
    "            self.square[row][column] = self.turn\n",
    "        self.turn = 2 if self.turn is 1 else 1\n",
    "    # 石がおけるかどうか\n",
    "    def putable(self, row, column):\n",
    "        if 0 <= row < self.size and 0 <= column < self.size:\n",
    "            return self.square[row][column] is 0\n",
    "        else:\n",
    "            return 0\n",
    "    # ゲーム終了判定(colorの勝ち)\n",
    "    def end_game(self, color):\n",
    "        direction = [[-1, -1], [-1, 0], [-1, 1], [0, -1], [0, 1], [1, -1], [1, 0], [-1 ,-1]]\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                for d in direction:\n",
    "                    if self.fives(color, i, j, d):\n",
    "                        return 1\n",
    "        return 0\n",
    "    # 五目がつながっている判定\n",
    "    def fives(self, color, i, j, d):\n",
    "        number = 0\n",
    "        while 0 <= i < self.size and 0 <= j < self.size and self.square[i][j] is color:\n",
    "            number += 1\n",
    "            i += d[0]\n",
    "            j += d[1]\n",
    "        if number >= 5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # 盤面を表示\n",
    "    def iout(self):\n",
    "        img = np.asarray([[[0, 256, 0] if i is 0 else [0, 0, 0] if i is 1 else [256, 256, 256] for i in l] for l in self.square])\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        \n",
    "    # ランダムの着手\n",
    "    def rand_put(self):\n",
    "        i, j = -1, -1\n",
    "        while (not 0 <= i < self.size) or (not 0 <= j < self.size) or not self.putable(i, j):\n",
    "            i, j = rd.randrange(self.size), rd.randrange(self.size)\n",
    "        self.put(i, j)\n",
    "    \n",
    "    # 次のありえるすべての盤面\n",
    "    def next_nodes(self):\n",
    "        n = []\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.putable(i, j):\n",
    "                    n.append(copy.deepcopy(self))\n",
    "                    n[-1].put(i, j)\n",
    "        return n\n",
    "    \n",
    "    # 入力による着手\n",
    "    def input_put(self):\n",
    "        i, j = -1, -1\n",
    "        while (not 0 <= i < self.size) or (not 0 <= j < self.size) or not self.putable(i, j):\n",
    "            i, j = map(int, input('input (row, column)').split())\n",
    "        self.put(i, j)\n",
    "    \n",
    "        \n",
    "g = Game()\n",
    "for _ in range(10):\n",
    "    g.rand_put()\n",
    "g.iout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLPモデル\n",
    "# def mlp(x):\n",
    "#     init = tf.variance_scaling_initializer()\n",
    "#     layer_1 = tf.layers.dense(x, size*size, activation=tf.nn.relu, kernel_initializer=init)\n",
    "#     layer_2 = tf.layers.dense(layer_1, size*size, activation=tf.nn.relu, kernel_initializer=init)\n",
    "#     layer_3 = tf.layers.dense(layer_2, size*size, activation=tf.nn.relu, kernel_initializer=init)\n",
    "#     out = tf.layers.dense(layer_3, 1, kernel_initializer=init)\n",
    "#     return out\n",
    "\n",
    "# CNNモデル\n",
    "def cnn(x):    # shape : [#sample, 784]\n",
    "    x_image = tf.reshape(x, [-1,size, size,1])    # [None, size, size, 1]\n",
    "    conv1 = tf.layers.conv2d(x_image, 64, (5,5), padding='same', activation=tf.nn.relu)    # [None, size, size, 64]\n",
    "    pool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2))    # [None, 14, 14, 32]\n",
    "    conv2 = tf.layers.conv2d(pool1, 128, (5,5), padding='same', activation=tf.nn.relu)    # [None, size/2, size/2, 128]\n",
    "    pool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2))    # [None, size/4, size/4, 128]\n",
    "    pool2_flat = tf.layers.flatten(pool2)    # [None, size/4*size/4*128 = size*size*8]\n",
    "    dense1 = tf.layers.dense(pool2_flat, 512, activation=tf.nn.relu)\n",
    "    y = tf.layers.dense(dense1, 1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-648d97b0e32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#tf.reset_default_graph()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# 計算グラフの構築\n",
    "n_epoch = 10000\n",
    "#tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, size*size])\n",
    "t = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "y = cnn(x)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(y - t))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "\n",
    "train_summary_loss = tf.summary.scalar('train_loss', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.4.10\n",
      "  latest version: 4.5.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /anaconda3/anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    tensorflow: 1.10.0-eigen_py36h0906837_0\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "import os\n",
    "model_path = './model/'\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "    \n",
    "# ログの保存\n",
    "import shutil\n",
    "logs_path = './log/'\n",
    "if os.path.exists(logs_path):\n",
    "    shutil.rmtree(logs_path)\n",
    "os.mkdir(logs_path)\n",
    "saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Win Rate 0.70\n",
      "epoch 0 | Train loss 1.0705\n",
      "epoch 1 | Train loss 0.0761\n",
      "epoch 2 | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f70869adfdab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0mx_game\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx_game\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0;31m# 着手の評価値を予測\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0mnext_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_game\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0msum_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# 確率的最適手\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m     \"\"\"\n\u001b[0;32m--> 707\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5211\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5212\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5213\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    trail = 0\n",
    "    for epoch in range(n_epoch):\n",
    "        # ランダムAIとテストする\n",
    "        if epoch % 10 == 0:\n",
    "            wins = 0\n",
    "            # 10回の対戦\n",
    "            for i in range(20):\n",
    "                g = Game()\n",
    "                # 盤面が全て埋まるまで対戦\n",
    "                for i in range(size*size):\n",
    "                    if i % 2 is 1:\n",
    "                        next_node = g.next_nodes()\n",
    "                        next_values = []\n",
    "                        for node in next_node:\n",
    "                            x_game = []\n",
    "                            for s in node.square:\n",
    "                                x_game.extend(s)\n",
    "                            x_game = [x_game]\n",
    "                            next_values.append(y.eval(feed_dict={x: x_game}, session=sess)[0])\n",
    "                        g = next_node[next_values.index(max(next_values))]\n",
    "                    else:\n",
    "                        next_node = g.next_nodes()\n",
    "                        g = next_node[rd.randrange(len(next_node))]\n",
    "                    # 白（AI）の勝ち\n",
    "                    if g.end_game(2):\n",
    "                        wins += 1\n",
    "                        break\n",
    "                    # 黒(ランダム)の勝ち\n",
    "                    if g.end_game(1):\n",
    "                        break\n",
    "                g = None\n",
    "            # 成績を記録\n",
    "            print('Test Win Rate %.2f' %(wins / 20))\n",
    "\n",
    "        #### 学習 ####\n",
    "        # 自己対戦で学習\n",
    "        print('epoch %d | ' % epoch, end='')\n",
    "        g = Game()  # 新しいゲームを定義\n",
    "        g_history = []  #着手毎に盤面を保存\n",
    "        win = 0   #白が勝ったら1, 黒が勝ったら2, 引き分けが0\n",
    "        loss = 0  #損失関数\n",
    "        for i in range(size*size):\n",
    "            # g.iout()\n",
    "            g_history.append(copy.deepcopy(g))  #クラスを使うときは、deepcopyでコピーを用意して、入れないと上書きされる\n",
    "            next_node = g.next_nodes()\n",
    "            next_values = []\n",
    "            \n",
    "            #特にモンテカルロ法を使う場合に注意する必要\n",
    "            #ランダム性を入れないと極小値に陥りやすい\n",
    "            #ランダム性を入れすぎると、学習率が下がり、負けだけを学習することになるかもしれない\n",
    "            \n",
    "            if rd.random() < 0.05:  #5%以下の確率でこっち\n",
    "                g.rand_put()\n",
    "            \n",
    "            else:  #95%の確率でこっち\n",
    "                # 着手の探索\n",
    "                for node in next_node: #ノードは、一回一回の盤面のこと\n",
    "                    x_game = []\n",
    "                    for s in node.square:\n",
    "                        x_game.extend(s)\n",
    "                    x_game = [x_game]\n",
    "                    # 着手の評価値を予測\n",
    "                    next_values.append(100**((-1 if i%2 == 0 else 1) * y.eval(feed_dict={x: x_game}, session=sess)[0]))\n",
    "                    # 偶数は黒。黒なら評価値に-1をかける。（逆数）＆ボルツマン分布\n",
    "                sum_value = sum(next_values)\n",
    "                # 確率的最適手\n",
    "                p_value, a_value = 0, rd.random()\n",
    "                index = 0\n",
    "                for ind, v in enumerate(next_values):#評価値が入った値に対して、\n",
    "                    p_value += v / sum_value  #右項：評価値の比、左項：累積値\n",
    "                    if p_value >= a_value:   #a_value:閾値\n",
    "                        index = ind\n",
    "                g = next_node[index]\n",
    "            \n",
    "            # ゲームの終了判定\n",
    "            if g.end_game(1):\n",
    "                win = 1\n",
    "                break\n",
    "            elif g.end_game(2):\n",
    "                win = 2\n",
    "                break\n",
    "\n",
    "        # 勝敗がついたときのみ学習---モンテカルロ法\n",
    "        if win is not 0:\n",
    "            x_batch = []\n",
    "            t_batch = []\n",
    "            # すべての盤面についてバッチを作る\n",
    "            for i, g_h in enumerate(g_history):\n",
    "                x_game = []\n",
    "                for s in g_h.square:\n",
    "                    x_game.extend(s)#1行1行追加して、1次元にしている。\n",
    "                x_batch.append(x_game)\n",
    "                q_value = [0] if win is 1 else [1]　#盤面のラベル。（白にとってどれくらい有利か？というラベル）黒が勝っていれば、0.白が勝っていれば1\n",
    "                t_batch.append(q_value)\n",
    "         #----       モンテカルロ法\n",
    "        \n",
    "            # 最適化(学習)\n",
    "            _, cost_, summary_loss = sess.run([optimizer, cost, train_summary_loss], feed_dict={x:x_batch, t:t_batch})#最適化はこの1文\n",
    "            summary_writer.add_summary(summary_loss, trail)#trailは何番目の学習データなのかを記録するために導入した\n",
    "            trail += 1\n",
    "            print('Train loss %.4f' %(cost_))\n",
    "            # モデルの保存\n",
    "            saver.save(sess, model_path)\n",
    "        else:\n",
    "            print('Draw')\n",
    "        g = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are missing from the target environment:\n",
      "  - tensorflow-gpu\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda remove tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard https://qiita.com/uosansatox/items/b552c9c4d8f1cebbf044"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
